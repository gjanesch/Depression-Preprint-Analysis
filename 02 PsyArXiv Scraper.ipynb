{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "import re\n",
    "from time import sleep\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import requests\n",
    "from selenium import webdriver\n",
    "from tqdm import tqdm\n",
    "\n",
    "SEARCH_URL = \"https://psyarxiv.com/discover?q=depression\"\n",
    "PsyArXivTuple = namedtuple(\"PsyArXivTuple\", \n",
    "                           field_names=[\"PaperName\",\"URL\",\"LastEdited\",\"Disciplines\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_page_html(url):\n",
    "    \"\"\"Shorthand for retrieving a page's HTML and processing it into BeautifulSoup.\"\"\"\n",
    "    return BeautifulSoup(requests.get(url).text, \"lxml\")\n",
    "\n",
    "\n",
    "def download_pdf(pdf_url, file_destination):\n",
    "    \"\"\"Downloads a single PDF file from the given URL\"\"\"\n",
    "    response = requests.get(pdf_url)\n",
    "    with open(file_destination,'wb') as f:\n",
    "        f.write(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get initial preprint info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the Selenium driver\n",
    "driver = webdriver.Firefox()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(SEARCH_URL)\n",
    "sleep(5)\n",
    "page_html = BeautifulSoup(driver.page_source, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pagination_element = page_html.find_all(\"ul\", attrs={\"class\":\"pagination\"})[-1]\n",
    "last_page_link = pagination_element.find_all(\"li\", attrs={\"class\":\"ember-view\"})[-1]\n",
    "number_of_pages = int(last_page_link.text.strip())\n",
    "number_of_pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OSF_paper_info(paper_element):\n",
    "    paper_link = paper_element.find(\"h4\")\n",
    "    if paper_link.a:\n",
    "        paper_name = paper_link.a.text.strip()\n",
    "        paper_url = paper_link.a[\"href\"]\n",
    "    else:\n",
    "        paper_name = paper_link.span.text.strip()\n",
    "        paper_url = \"\"\n",
    "        \n",
    "    last_edited = paper_element.find(\"em\").text.strip()[13:-4]\n",
    "    \n",
    "    discipline_elements = paper_element.find_all(\"span\", attrs={\"class\":\"subject-preview\"})\n",
    "    if discipline_elements:\n",
    "        disciplines = [e.text.strip() for e in discipline_elements]\n",
    "    else:\n",
    "        disciplines = []\n",
    "        \n",
    "    return PsyArXivTuple(paper_name, paper_url, last_edited, disciplines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [08:06<00:00,  5.35s/it]\n"
     ]
    }
   ],
   "source": [
    "preprint_tuples = []\n",
    "for page in tqdm(range(number_of_pages)):\n",
    "    target_page = f\"https://psyarxiv.com/discover?page={page+1}&q=depression\"\n",
    "    driver.get(target_page)\n",
    "    sleep(5)  ## try to avoid overwhelming the site\n",
    "    \n",
    "    page_html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    papers_on_page = page_html.find_all(\"div\", attrs={\"class\": \"col-sm-8\"})[1]\n",
    "    paper_elements = papers_on_page.find_all(\"div\", attrs={\"class\":\"ember-view\"}, recursive=False)\n",
    "    current_page_tuples = [get_OSF_paper_info(p) for p in paper_elements]\n",
    "    preprint_tuples.extend(current_page_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "psyarxiv = pd.DataFrame(preprint_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(psyarxiv[\"URL\"] == \"\").mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "psyarxiv.to_csv(\"psyarxiv.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the preprints themselves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "psyarxiv = pd.read_csv(\"psyarxiv.csv\", converters={\"Disciplines\":eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "64it [07:41,  7.22s/it]\n"
     ]
    }
   ],
   "source": [
    "save_directory = \"preprints/\"\n",
    "tag_lists = []\n",
    "for _, row in tqdm(psyarxiv.iterrows()):\n",
    "    driver.get(row.URL)\n",
    "    sleep(5)\n",
    "    page_html = BeautifulSoup(driver.page_source, \"lxml\")\n",
    "    \n",
    "    #get file extension & use preprint title on \n",
    "    if (file_name_element := page_html.find(\"span\", attrs={\"id\":\"selectedFileName\"})):\n",
    "        file_name = file_name_element.text\n",
    "        extension = re.match(\"^.*?\\.\", file_name[::-1]).group()[::-1]\n",
    "        paper_name = row.PaperName.replace(\"/\", \"-\").replace(\":\", \"\")\n",
    "        if len(paper_name) > 250:\n",
    "            paper_name = paper_name[:250]\n",
    "        download_pdf(row.URL + \"download\", save_directory + paper_name + extension)\n",
    "        tags = page_html.find_all(\"span\", attrs={\"class\":\"badge\"})\n",
    "    else:\n",
    "        tags = []\n",
    "    \n",
    "    tag_lists.append([t.text for t in tags])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "psyarxiv[\"Tags\"] = tag_lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "psyarxiv.to_csv(\"psyarxiv.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
